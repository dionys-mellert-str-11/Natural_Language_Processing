# Natural Language Processing

What is Natural Language Processing (NLP) ? <br>
Natural Language Processing (NLP) is a subject of Artificial Intelligence that is focused in giving a computer the ability to process, understand and learn from text.

What are the terms normally used in NLP ? <br>
    - test
- 
4. What are Corpus, Tokens, and Engrams?
   a.What is Tokenization?
3.What is White-space Tokenization?
4.What is Regular Expression Tokenization?
5.What is Normalization?
6.What is Stemming?
7.What is Lemmatization?
8.Part of Speech tags in NLP
9.Grammar in NLP and its types
10.What is Dependency Grammar?

Natural Language Processing (NLP) is a branch of artificial intelligence that is concerned with giving computers the ability to understand the text and spoken words in pretty much the same way human beings can. designed to help machines learn from text.
