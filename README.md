# Natural Language Processing

What is Natural Language Processing (NLP) ? <br>
It is a subject of Artificial Intelligence that is focused in giving a computer the ability to process, understand and learn from text. <br>

What are the terms normally used in NLP ? <br>
1. Corpus, Tokens, and Engrams <br>
  - Corpus can be define as a collection of structured text in written or spoken form. <br>
  - Tokens is an instance of a sequence of characters in some particular document that are grouped together as a useful semantic unit for processing, for example: never give up. <br>
  - Engrams, using "never give up" as an example <br>
    * uni-grams (n=1), never, give, up (it represents one word). <br>
    * di-grams (n=2), never give, give up (it represents 2 words together). <br>
    * tri-grams (n=3), never give up (it represents 3 words together). <br>
2. Tokenization <br>
  - Tokenization is used to split paragraphs and sentences into smaller units that can be more easily assigned meaning, using previous example: 3 tokens – Never-give-up. Tokenization can be categorized into 2: white-space tokenization and regular expression tokenization. <br>
    * white-space tokenization, text is split into words by splitting them from white spaces. <br>
      - for example: "my home address is Dionys-Mellert-Strasse" <br>
      - it will be splitted into following tokens: "my", "home", "address", "is", "Dionys-Mellert-Strasse" <br>
      - remark: "Dionys-Mellert-Strasse" is not split because the tokenization process was based on whitespaces only <br>
    * regular expression tokenization, it splits a string into substrings using a regular expression <br>
      - for example: "Good sausagges cost €3.5\nin Frankfurt. <br>
      - it will be splitted into following tokens: "Good", "saussages", "cost", €3.5", "in", "Frankfurt", "." <br>

3. Normalization
6. Stemming
7. Lemmatization
8. Part of Speech tags in NLP
9. Grammar in NLP and its types
10. Dependency Grammar

